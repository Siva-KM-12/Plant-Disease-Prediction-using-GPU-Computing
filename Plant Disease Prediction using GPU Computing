import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import time
from google.colab import drive
import matplotlib.pyplot as plt

drive.mount('/content/drive')

train_dir = '/content/drive/MyDrive/Colab Notebooks/Plant_Dataset/train_dataset'
val_dir = '/content/drive/MyDrive/Colab Notebooks/Plant_Dataset/test_dataset'

transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])

train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)
val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

class CNNModel(nn.Module):
    def __init__(self, num_classes):
        super(CNNModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(128 * 16 * 16, 128)
        self.fc2 = nn.Linear(128, num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = self.pool(torch.relu(self.conv3(x)))
        x = x.view(-1, 128 * 16 * 16)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

num_classes = len(train_dataset.classes)
model = CNNModel(num_classes)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def custom_cuda_kernel(input_tensor):
    device = input_tensor.device
    output_tensor = torch.empty_like(input_tensor)  
   
    if device.type == 'cuda':
        output_tensor = input_tensor.pow(2) 
    else:
        output_tensor = input_tensor.pow(2)  

    return output_tensor

device_cpu = torch.device('cpu')
model.to(device_cpu)
train_losses_serial = []
val_losses_serial = []

start_time = time.time()

for epoch in range(5):  
    train_loss = 0.0
    model.train()
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device_cpu), labels.to(device_cpu)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
    train_losses_serial.append(train_loss / len(train_loader))

    val_loss = 0.0
    model.eval()
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device_cpu), labels.to(device_cpu)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
    val_losses_serial.append(val_loss / len(val_loader))
    
    print(f"Serial Epoch [{epoch+1}/5] - Train Loss: {train_losses_serial[-1]}, Val Loss: {val_losses_serial[-1]}")

end_time = time.time()
serial_execution_time = end_time - start_time
print("Serial Execution Time on CPU: {:.2f} seconds".format(serial_execution_time))


device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model.to(device_gpu)

optimizer = optim.Adam(model.parameters(), lr=0.001)

train_losses_parallel = []
val_losses_parallel = []

start_time = time.time()

for epoch in range(5):  
    train_loss = 0.0
    model.train()
    for inputs, labels in train_loader:
      
        inputs, labels = inputs.to(device_gpu), labels.to(device_gpu)

        inputs = custom_cuda_kernel(inputs)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
    train_losses_parallel.append(train_loss / len(train_loader))

    val_loss = 0.0
    model.eval()
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device_gpu), labels.to(device_gpu)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
    val_losses_parallel.append(val_loss / len(val_loader))
    
    print(f"Parallel Epoch [{epoch+1}/5] - Train Loss: {train_losses_parallel[-1]}, Val Loss: {val_losses_parallel[-1]}")

end_time = time.time()
parallel_execution_time = end_time - start_time
print("Parallel Execution Time on GPU: {:.2f} seconds".format(parallel_execution_time))

print("Speedup from GPU Parallelization: {:.2f}x".format(serial_execution_time / parallel_execution_time))


plt.figure(figsize=(10, 4))
plt.bar(['CPU (Serial)', 'GPU (Parallel)'], [serial_execution_time, parallel_execution_time], color=['blue', 'green'])
plt.ylabel('Execution Time (seconds)')
plt.title('Serial vs Parallel Execution Time')
plt.show()

epochs = range(1, 6)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(epochs, train_losses_serial, label='Train Loss (Serial)', color='blue')
plt.plot(epochs, val_losses_serial, label='Val Loss (Serial)', color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss (Serial Execution)')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, train_losses_parallel, label='Train Loss (Parallel)', color='green')
plt.plot(epochs, val_losses_parallel, label='Val Loss (Parallel)', color='red')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss (Parallel Execution)')
plt.legend()

plt.tight_layout()
plt.show()
